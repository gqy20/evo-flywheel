# å¤šæ™ºèƒ½ä½“ç«äº‰æ¡†æ¶è®¾è®¡æ–‡æ¡£

> **é¡¹ç›®**: Evo-Flywheel å­¦æœ¯é£è½®ç³»ç»Ÿ
> **æ–‡æ¡£ç±»å‹**: æŠ€æœ¯è®¾è®¡æ–‡æ¡£
> **ç‰ˆæœ¬**: v1.0
> **åˆ›å»ºæ—¥æœŸ**: 2025-12-28
> **çŠ¶æ€**: è®¾è®¡é˜¶æ®µ

---

## 1. èƒŒæ™¯ä¸åŠ¨æœº

### 1.1 é—®é¢˜å®šä¹‰

**ä¼ ç»Ÿæ¨èç³»ç»Ÿçš„å±€é™ï¼š**

å½“å‰å­¦æœ¯æ–‡çŒ®æ¨èç³»ç»Ÿå­˜åœ¨ä»¥ä¸‹é—®é¢˜ï¼š

1. **å°é—­å¾ªç¯**ï¼šç”¨æˆ·ç‚¹å‡» â†’ ä¼˜åŒ–æ¨è â†’ æ›´å¤šç‚¹å‡»ï¼Œå¯èƒ½é™·å…¥å±€éƒ¨æœ€ä¼˜
2. **å•ä¸€ä»·å€¼**ï¼šä»¥ç”¨æˆ·åå¥½ä¸ºå¯¼å‘ï¼Œè€ŒéçœŸå®å­¦æœ¯ä»·å€¼
3. **ç¼ºä¹éªŒè¯**ï¼šæ— æ³•é¢„æµ‹è®ºæ–‡çš„çœŸå®å½±å“åŠ›
4. **è¿‡æ»¤æ°”æ³¡**ï¼šè¿‡åº¦è¿åˆç”¨æˆ·å†å²ï¼Œé™åˆ¶å‘ç°èŒƒå›´

### 1.2 å¯å‘ï¼šAI-Trader å¤šæ¨¡å‹äº¤æ˜“å®éªŒ

**AI-Trader (é¦™æ¸¯å¤§å­¦)**

| é¡¹ç›® | è¯¦æƒ… |
|------|------|
| **ä¸»åŠæ–¹** | é¦™æ¸¯å¤§å­¦æ•°æ®ç§‘å­¦å­¦é™¢ (é»„è¶…æ•™æˆ) |
| **GitHub** | https://github.com/HKUDS/AI-Trader |
| **ç›´æ’­å¹³å°** | https://ai4trade.ai |

**å®éªŒè®¾è®¡ï¼š**

- 5ä¸ªAIæ¨¡å‹ï¼ˆQwen, DeepSeek, GPT, Claude, Geminiï¼‰å„æŒ$10,000
- åœ¨NASDAQ 100å¸‚åœºç‹¬ç«‹äº¤æ˜“ï¼Œé›¶äººå·¥å¹²é¢„
- éµå¾ª"ä¸‰ä¸åŸåˆ™"ï¼šä¸å¹²é¢„ã€ä¸åŠ æ æ†ã€ä¸åšç©º

**å®éªŒç»“æœï¼š**

| æ’å | æ¨¡å‹ | æ”¶ç›Šç‡ | ç‰¹å¾ |
|------|------|--------|------|
| ğŸ¥‡ | Qwen 3 Max | +22.32% | ç¨³å¥æ³¢æ®µæ“ä½œ |
| ğŸ¥ˆ | DeepSeek V3.1 | +4.89% | ç²¾å‡†æŠ„åº• |
| 3 | Grok 4 | å°å¹…äºæŸ | - |
| 4 | Claude Sonnet 4.5 | äºæŸ | è¿‡äºä¿å®ˆ |
| 5 | Gemini 2.5 Pro | å¤§å¹…äºæŸ | ç­–ç•¥æ··ä¹± |
| 6 | **GPT-5** | **-62%** | é«˜é¢‘è¿‡åº¦äº¤æ˜“ |

**å…³é”®å‘ç°ï¼š**

1. **ç­–ç•¥å·®å¼‚æš´éœ²**ï¼šä¸åŒæ¨¡å‹æœ‰å¤©ç„¶ä¸åŒçš„äº¤æ˜“é£æ ¼
2. **çœŸå®å¸‚åœºéªŒè¯**ï¼šå®é™…æ”¶ç›Šä½œä¸ºå®¢è§‚è¯„ä»·æ ‡å‡†
3. **ç«äº‰é©±åŠ¨è¿›åŒ–**ï¼šå¯è¯†åˆ«æœ‰æ•ˆç­–ç•¥å¹¶è°ƒæ•´æƒé‡
4. **é€æ˜å¯è§†åŒ–**ï¼šæ’è¡Œæ¦œå½¢æˆæŒç»­æ¿€åŠ±

---

## 2. æ ¸å¿ƒè®¾è®¡ç†å¿µ

### 2.1 ä»äº¤æ˜“åˆ°å­¦æœ¯çš„æ˜ å°„

| é‡‘èå¸‚åœº | å­¦æœ¯å¸‚åœº |
|----------|----------|
| è‚¡ç¥¨ä»·æ ¼ | è®ºæ–‡å½±å“åŠ› |
| ä¹°å…¥/å–å‡º | å…³æ³¨/å¿½ç•¥ |
| æ¶¨è·Œå¹… | å¼•ç”¨å¢é•¿ |
| äº¤æ˜“é‡ | ä¸‹è½½/æµè§ˆé‡ |
| æ”¶ç›Šç‡ | é¢„æµ‹å‡†ç¡®ç‡ |
| ç ´äº§ | è¢«æ’¤ç¨¿/è¯ä¼ª |

### 2.2 å¤šæ™ºèƒ½ä½“ç«äº‰æ¡†æ¶

**æ ¸å¿ƒç†å¿µè½¬å˜ï¼š**

```
ä¼ ç»Ÿæ¨¡å¼:
å•ä¸€æ¨èç³»ç»Ÿ â†’ ä¼˜åŒ–ç”¨æˆ·ç‚¹å‡» â†’ å°é—­å¾ªç¯

ç«äº‰æ¨¡å¼:
å¤šä¸ªæ™ºèƒ½ä½“ â†’ é¢„æµ‹çœŸå®å½±å“ â†’ çœŸå®éªŒè¯ â†’ ç­–ç•¥è¿›åŒ– â†’ å¼€æ”¾é£è½®
```

**ä¸‰å±‚åé¦ˆç»“æ„ï¼š**

```
Layer 1: æ™ºèƒ½ä½“å±‚ (AI vs AI)
  å¤šä¸ªè¯„ä¼°æ™ºèƒ½ä½“ç«äº‰é¢„æµ‹
  â†“
Layer 2: ç”¨æˆ·å±‚ (Human vs AI)
  ç”¨æˆ·å‚ä¸é¢„æµ‹ï¼Œå½¢æˆäºŒçº§ç«äº‰
  â†“
Layer 3: çœŸå®ä¸–ç•Œ (Nature vs All)
  å­¦æœ¯å¸‚åœºä½œä¸ºç»ˆæä»²è£è€…
  â†“
  åé¦ˆåˆ° Layer 1 å’Œ 2
  â†“
  é£è½®åŠ é€Ÿ
```

---

## 3. æ™ºèƒ½ä½“è§’è‰²ä½“ç³»

### 3.1 è§’è‰²è®¾è®¡çŸ©é˜µ

```
        ä¿å®ˆ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” æ¿€è¿›
         â†‘                          â†‘
    ç†è®º  Aå‹                   Cå‹
    å®ˆæŠ¤è€…              èŒƒå¼è½¬ç§»çŒæ‰‹
    (ä¿å®ˆ+ç†è®º)          (æ¿€è¿›+ç†è®º)
         â†“                          â†“
    Bå‹                   Då‹
    å®ç”¨ä¸»ä¹‰è€…             æŠ€æœ¯é¢ è¦†è€…
    (ä¿å®ˆ+åº”ç”¨)          (æ¿€è¿›+åº”ç”¨)
         â†“                          â†“
        åº”ç”¨ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” ç†è®º
```

### 3.2 å››ä¸ªåŸºç¡€æ™ºèƒ½ä½“

| æ™ºèƒ½ä½“ | è§’è‰²å | å…³æ³¨ç‚¹ | é¢„æµ‹æ¨¡å¼ | é«˜åˆ†åœºæ™¯ |
|--------|--------|--------|----------|----------|
| **Aå‹** | ç†è®ºå®ˆæŠ¤è€… | æ–¹æ³•è®ºä¸¥è°¨æ€§ã€ç»Ÿè®¡æ˜¾è‘—æ€§ | ä¿å®ˆé¢„æµ‹ | æ ‡å‡†åŒ–ç ”ç©¶çš„çªç ´ |
| **Bå‹** | å®ç”¨ä¸»ä¹‰è€… | å®é™…åº”ç”¨ä»·å€¼ã€å·¥ç¨‹å¯è¡Œæ€§ | é€‚ä¸­é¢„æµ‹ | åº”ç”¨ä¼˜åŒ–è®ºæ–‡ |
| **Cå‹** | èŒƒå¼è½¬ç§»çŒæ‰‹ | é¢ è¦†æ€§åˆ›æ–°ã€ç†è®ºçªç ´ | æ¿€è¿›é¢„æµ‹ | å¼€åˆ›æ–°é¢†åŸŸ |
| **Då‹** | æŠ€æœ¯é¢ è¦†è€… | æŠ€æœ¯åˆ›æ–°ã€å·¥å…·ä»·å€¼ | æ¿€è¿›é¢„æµ‹ | æ–°æŠ€æœ¯åº”ç”¨ |

### 3.3 æ™ºèƒ½ä½“é¢„æµ‹æ¨¡å¼ç¤ºä¾‹

**åŒä¸€ç¯‡è®ºæ–‡ï¼Œä¸åŒæ™ºèƒ½ä½“çš„é¢„æµ‹ï¼š**

```python
è®ºæ–‡: "CRISPR-Cas9åœ¨æ¤ç‰©åŸºå› ç»„ç¼–è¾‘ä¸­çš„æ–°æ–¹æ³•"

æ™ºèƒ½ä½“é¢„æµ‹:
â”œâ”€â”€ Aå‹ (ç†è®ºå®ˆæŠ¤è€…)
â”‚   â”œâ”€â”€ é¢„æµ‹å¼•ç”¨: 15
â”‚   â”œâ”€â”€ ç†ç”±: æ–¹æ³•æ ‡å‡†ä½†æ— ç†è®ºçªç ´
â”‚   â””â”€â”€ è¯„åˆ†: 6/10
â”‚
â”œâ”€â”€ Bå‹ (å®ç”¨ä¸»ä¹‰è€…)
â”‚   â”œâ”€â”€ é¢„æµ‹å¼•ç”¨: 35
â”‚   â”œâ”€â”€ ç†ç”±: æœ‰å®é™…åº”ç”¨ä»·å€¼
â”‚   â””â”€â”€ è¯„åˆ†: 7/10
â”‚
â”œâ”€â”€ Cå‹ (èŒƒå¼è½¬ç§»çŒæ‰‹)
â”‚   â”œâ”€â”€ é¢„æµ‹å¼•ç”¨: 25
â”‚   â”œâ”€â”€ ç†ç”±: éèŒƒå¼è½¬ç§»ï¼Œå±æ¸è¿›æ”¹è¿›
â”‚   â””â”€â”€ è¯„åˆ†: 6/10
â”‚
â””â”€â”€ Då‹ (æŠ€æœ¯é¢ è¦†è€…)
    â”œâ”€â”€ é¢„æµ‹å¼•ç”¨: 60
    â”œâ”€â”€ ç†ç”±: æ–°æŠ€æœ¯ï¼Œå¯èƒ½è¢«å¹¿æ³›é‡‡ç”¨
    â””â”€â”€ è¯„åˆ†: 8/10

åˆ†æ­§åº¦: 45 (é«˜ï¼å€¼å¾—å…³æ³¨)
å…±è¯†: 33.75
```

---

## 4. é¢„æµ‹å¸‚åœºç«äº‰æœºåˆ¶

### 4.1 é¢„æµ‹åˆçº¦è®¾è®¡

```python
# ä¼ªä»£ç ï¼šé¢„æµ‹åˆçº¦ç³»ç»Ÿ
class PredictionContract:
    """è®ºæ–‡å½±å“åŠ›é¢„æµ‹åˆçº¦"""

    def __init__(self, paper):
        self.paper_id = paper["id"]
        self.opening_date = datetime.now()

        # å„æ™ºèƒ½ä½“é¢„æµ‹
        self.predictions = {}
        for agent in agents:
            self.predictions[agent.name] = {
                "citations_1year": agent.predict_impact(paper),
                "confidence": agent.get_confidence(),
                "reasoning": agent.explain_prediction(paper),
            }

        # è®¡ç®—åˆ†æ­§åº¦
        self.disagreement = self._calculate_disagreement()
        self.consensus = np.mean([p["citations_1year"]
                                  for p in self.predictions.values()])

    def _calculate_disagreement(self):
        """è®¡ç®—é¢„æµ‹åˆ†æ­§åº¦"""
        preds = [p["citations_1year"] for p in self.predictions.values()]
        return max(preds) - min(preds)

    def validate(self, actual_citations):
        """çœŸå®éªŒè¯ï¼Œæ›´æ–°æ™ºèƒ½ä½“å£°èª‰"""
        for agent_name, prediction in self.predictions.items():
            error = abs(prediction["citations_1year"] - actual_citations)
            agents[agent_name].update_reputation(error)
```

### 4.2 åˆ†æ­§åº¦çš„ä»·å€¼ä¿¡å·

| åˆ†æ­§åº¦èŒƒå›´ | å«ä¹‰ | ç”¨æˆ·è¡Œä¸º | å­¦æœ¯ä»·å€¼ |
|-----------|------|----------|----------|
| é«˜ (>50) | æ™ºèƒ½ä½“æ„è§ä¸¥é‡åˆ†æ­§ | æ·±å…¥é˜…è¯»ã€è‡ªè¡Œåˆ¤æ–­ | å¯èƒ½æœ‰äº‰è®®æˆ–çªç ´ |
| ä¸­ (20-50) | æ­£å¸¸è§‚ç‚¹å·®å¼‚ | å€¼å¾—æµè§ˆ | å¸¸è§„ç ”ç©¶ |
| ä½ (<20) | æ™ºèƒ½ä½“å…±è¯† | å¯å¿½ç•¥ | å¹³åº¸æˆ–æ˜æ˜¾çªç ´ |
| ä½+é«˜åˆ† | æ˜ç¡®çš„çªç ´è®ºæ–‡ | å¿…è¯» | é¢†åŸŸé‡è¦æˆæœ |

### 4.3 åˆ†å±‚éªŒè¯ä½“ç³»

| æ—¶é—´ç‚¹ | éªŒè¯æŒ‡æ ‡ | æƒé‡ | åé¦ˆå‘¨æœŸ |
|--------|----------|------|----------|
| **T+1å‘¨** | Altmetricè¯„åˆ†ã€æ—©æœŸè®¨è®º | 10% | 1å‘¨ |
| **T+1æœˆ** | æ—©æœŸå¼•ç”¨ã€ä¸‹è½½é‡ | 20% | 1æœˆ |
| **T+3æœˆ** | Q1å¼•ç”¨ã€ä¸“åˆ©æåŠ | 30% | 3æœˆ |
| **T+1å¹´** | æ­£å¼å¼•ç”¨æ•° | 40% | 1å¹´ |
| **T+3å¹´** | ç¨³å®šå¼•ç”¨ã€è¡ç”Ÿç ”ç©¶ | é•¿æœŸ | 3å¹´ |

---

## 5. å¤šç»´åº¦è¯„ä¼°æŒ‡æ ‡ä½“ç³»

### 5.1 ä¼ ç»Ÿå­¦æœ¯æŒ‡æ ‡

| æŒ‡æ ‡ | å«ä¹‰ | è·å–å‘¨æœŸ | é¢„æµ‹ä»·å€¼ |
|------|------|----------|----------|
| **æ€»å¼•ç”¨æ•°** | è¢«å…¶ä»–è®ºæ–‡å¼•ç”¨æ¬¡æ•° | 1-3å¹´ | æ ¸å¿ƒæŒ‡æ ‡ |
| **å¹´å‡å¼•ç”¨æ•°** | æ€»å¼•ç”¨/å‘è¡¨å¹´æ•° | 1-3å¹´ | æ ‡å‡†åŒ– |
| **å¼•ç”¨é€Ÿåº¦** | é¦–å¼•æ—¶é—´ã€å¼•ç”¨åŠè¡°æœŸ | 3-12æœˆ | æ—©æœŸä¿¡å· |
| **PRå€¼** | å¼•ç”¨ç½‘ç»œä¸­çš„é‡è¦æ€§ | 1-2å¹´ | è´¨é‡æƒé‡ |

### 5.2 æ›¿ä»£è®¡é‡å­¦

| ç»´åº¦ | å…·ä½“æŒ‡æ ‡ | æ•°æ®æº | åé¦ˆå‘¨æœŸ |
|------|----------|--------|----------|
| **æ–°é—»åª’ä½“** | æŠ¥é“æ•°ã€åª’ä½“å½±å“åŠ› | Altmetric | 1-7å¤© |
| **ç¤¾äº¤åª’ä½“** | Twitter, Weibo æåŠ | Altmetric API | 1å°æ—¶-3å¤© |
| **åšå®¢/è®ºå›** | ç§‘å­¦åšå®¢ã€Reddit | Altmetric | 1-3å¤© |
| **çŸ¥è¯†åº“** | Wikipedia, StackOverflow | API | 1-30å¤© |
| **å‚è€ƒç®¡ç†** | Mendeley, Zotero | Altmetric | 1-7å¤© |

### 5.3 æŠ€æœ¯å½±å“åŠ›

| æŒ‡æ ‡ | æ•°æ®æº | é€‚ç”¨é¢†åŸŸ | åé¦ˆå‘¨æœŸ |
|------|--------|----------|----------|
| **ä»£ç å½±å“** | GitHub stars/forks | è®¡ç®—æœºç§‘å­¦ | 1å‘¨-1æœˆ |
| **æ•°æ®ä¸‹è½½** | Zenodo, Figshare | æ•°æ®å¯†é›†å‹ | 1å‘¨-1æœˆ |
| **Dockerä½¿ç”¨** | Docker Hub pulls | è½¯ä»¶å·¥å…· | 1å‘¨-1æœˆ |
| **ä¸“åˆ©å¼•ç”¨** | Google Patents | åº”ç”¨ç§‘å­¦ | 1-3å¹´ |
| **ä¸´åºŠé‡‡ç”¨** | ä¸´åºŠæŒ‡å— | åŒ»å­¦ | 2-5å¹´ |

### 5.4 å†…å®¹è´¨é‡æŒ‡æ ‡

| ç»´åº¦ | è¯„ä¼°æ–¹æ³• | é¢„æµ‹ç›®æ ‡ |
|------|----------|----------|
| **æ–¹æ³•å­¦ä¸¥è°¨æ€§** | æ™ºèƒ½ä½“åˆ†æ | é•¿æœŸå¼•ç”¨ç¨³å®šæ€§ |
| **ç»Ÿè®¡åŠŸæ•ˆ** | æå–æ ·æœ¬é‡/æ•ˆåº”é‡ | å¯é‡å¤æ€§ |
| **å¯é‡å¤æ€§** | ä»£ç /æ•°æ®å¯ç”¨æ€§ | åç»­ç ”ç©¶åŸºç¡€ |
| **åˆ›æ–°æ€§** | ä¸å·²æœ‰æ–‡çŒ®è·ç¦» | çªç ´æ€§å¼•ç”¨ |
| **å¯è¯»æ€§** | NLPè¯­è¨€æ¨¡å‹ | ç¤¾ä¼šä¼ æ’­åŠ› |

### 5.5 é•¿æœŸè¡ç”Ÿå½±å“

| æŒ‡æ ‡ | æ—¶é—´çª—å£ | è¯„ä¼°æ–¹æ³• |
|------|----------|----------|
| **å¼€å¯æ–°é¢†åŸŸ** | 5-10å¹´ | ä¸“å®¶æ ‡æ³¨ |
| **æ”¹å˜æ•™ç§‘ä¹¦** | 5-15å¹´ | æ–‡æœ¬åˆ†æ |
| **åç»­é«˜è¢«å¼•** | 3-10å¹´ | ç½‘ç»œåˆ†æ |
| **åé©³è®ºæ–‡æ•°** | 1-5å¹´ | æƒ…æ„Ÿåˆ†æ |
| **ç»¼è¿°æ”¶å½•** | 2-5å¹´ | æ–‡æœ¬æŒ–æ˜ |

---

## 6. ç»¼åˆå½±å“åŠ›æŒ‡æ•°

### 6.1 åˆ†é¢†åŸŸåŠ æƒ

```python
def calculate_impact_score(paper, field="evolutionary_biology"):
    """è®¡ç®—ç»¼åˆå½±å“åŠ›æŒ‡æ•°"""

    # æ ‡å‡†åŒ–å„ç»´åº¦æŒ‡æ ‡ (0-100)
    normalized_metrics = {
        "citations": normalize(paper.citations, field_benchmark),
        "altmetric": normalize(paper.altmetric_score),
        "technical": normalize(paper.github_stars, dataset_downloads),
        "quality": paper.methodology_score * 10,
        "long_term": paper.innovation_score * 10,
    }

    # åˆ†é¢†åŸŸæƒé‡
    weights = {
        "basic_research": {  # åŸºç¡€ç ”ç©¶
            "citations": 0.40,
            "altmetric": 0.20,
            "technical": 0.10,
            "quality": 0.20,
            "long_term": 0.10,
        },
        "applied_research": {  # åº”ç”¨ç ”ç©¶
            "citations": 0.25,
            "altmetric": 0.15,
            "technical": 0.35,  # æ›´é‡è§†åº”ç”¨
            "quality": 0.15,
            "long_term": 0.10,
        },
    }

    w = weights.get(field, weights["basic_research"])
    return sum(normalized_metrics[k] * w[k] for k in normalized_metrics)
```

### 6.2 é¢„æµ‹ç›®æ ‡åˆ†å±‚

**çŸ­æœŸ (1-3ä¸ªæœˆ) - å¿«é€Ÿåé¦ˆï¼š**
- âœ… Altmetricè¯„åˆ†
- âœ… ä»£ç ä»“åº“ stars
- âœ… ä¸‹è½½é‡
- âœ… ç¤¾äº¤åª’ä½“è®¨è®º

**ä¸­æœŸ (1å¹´) - å­¦æœ¯éªŒè¯ï¼š**
- âœ… æ—©æœŸå¼•ç”¨æ•°
- âœ… ä¸“åˆ©å¼•ç”¨
- âœ… ç»¼è¿°æ”¶å½•

**é•¿æœŸ (3-5å¹´) - çœŸå®å½±å“ï¼š**
- âœ… ç¨³å®šå¼•ç”¨æ•°
- âœ… çŸ¥è¯†è¡ç”Ÿï¼ˆé«˜è¢«å¼•çš„å¼•ç”¨è€…ï¼‰
- âœ… æ•™æ/æŒ‡å—æ”¶å½•

---

## 7. æŠ€æœ¯å®ç°æ–¹æ¡ˆ

### 7.1 æ–°å¢æ¨¡å—ç»“æ„

```
src/evo_flywheel/
â”œâ”€â”€ analyzers/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base.py              # æ™ºèƒ½ä½“åŸºç±»
â”‚   â”‚   â”œâ”€â”€ conservative.py       # ä¿å®ˆæ´¾æ™ºèƒ½ä½“
â”‚   â”‚   â”œâ”€â”€ radical.py            # æ¿€è¿›æ´¾æ™ºèƒ½ä½“
â”‚   â”‚   â””â”€â”€ prompts.py            # è§’è‰²ç‰¹å®šPrompt
â”‚   â”œâ”€â”€ arena.py                  # ç«äº‰åœºåè°ƒå™¨
â”‚   â””â”€â”€ predictions.py            # é¢„æµ‹ç®¡ç†
â”œâ”€â”€ db/
â”‚   â”œâ”€â”€ models.py                 # æ–°å¢é¢„æµ‹/éªŒè¯è¡¨
â”‚   â””â”€â”€ predictions_crud.py       # é¢„æµ‹æ•°æ®æ“ä½œ
â””â”€â”€ validation/
    â”œâ”€â”€ altmetric.py              # Altmetricæ•°æ®è·å–
    â”œâ”€â”€ crossref.py               # å¼•ç”¨æ•°æ®è·å–
    â””â”€â”€ scheduler.py              # éªŒè¯è°ƒåº¦ä»»åŠ¡
```

### 7.2 æ ¸å¿ƒä»£ç æ¡†æ¶

**æ™ºèƒ½ä½“åŸºç±»ï¼š**

```python
# src/evo_flywheel/analyzers/agents/base.py
from abc import ABC, abstractmethod
from typing import Any

class PaperAgent(ABC):
    """è®ºæ–‡è¯„ä¼°æ™ºèƒ½ä½“åŸºç±»"""

    def __init__(self, name: str, role: str):
        self.name = name
        self.role = role  # "conservative_theory", "radical_app", etc.
        self.accuracy_history = []
        self.reputation_score = 0.5  # 0-1

    @abstractmethod
    def predict_impact(self, paper: dict[str, Any]) -> int:
        """é¢„æµ‹è®ºæ–‡1å¹´åçš„å¼•ç”¨æ•°"""
        pass

    @abstractmethod
    def analyze_paper(self, paper: dict[str, Any]) -> dict[str, Any]:
        """ä»ç‰¹å®šè§’åº¦åˆ†æè®ºæ–‡"""
        pass

    def get_confidence(self) -> float:
        """è¿”å›é¢„æµ‹ç½®ä¿¡åº¦"""
        if not self.accuracy_history:
            return 0.5
        # åŸºäºå†å²å‡†ç¡®ç‡è®¡ç®—
        recent_accuracy = np.mean(self.accuracy_history[-10:])
        return recent_accuracy

    def update_reputation(self, error: float) -> None:
        """åŸºäºé¢„æµ‹è¯¯å·®æ›´æ–°å£°èª‰"""
        # è½¬æ¢è¯¯å·®ä¸ºåˆ†æ•° (0-1, 1ä¸ºå®Œç¾)
        score = 1 / (1 + error / 10)
        self.accuracy_history.append(score)
        self.reputation_score = np.mean(self.accuracy_history[-50:])
```

**ä¿å®ˆæ´¾æ™ºèƒ½ä½“å®ç°ï¼š**

```python
# src/evo_flywheel/analyzers/agents/conservative.py
from evo_flywheel.analyzers.agents.base import PaperAgent
from evo_flywheel.analyzers.llm import analyze_paper
from evo_flywheel.analyzers.agents.prompts import CONSERVATIVE_THEORY_PROMPT

class ConservativeTheoryAgent(PaperAgent):
    """ä¿å®ˆæ´¾ç†è®ºæ™ºèƒ½ä½“ - ç†è®ºå®ˆæŠ¤è€…"""

    def __init__(self):
        super().__init__(
            name="Conservative_Theory",
            role="ä¿å®ˆæ´¾ç†è®º"
        )

    def predict_impact(self, paper: dict[str, Any]) -> int:
        """ä¿å®ˆé¢„æµ‹å¼•ç”¨æ•°"""
        # è·å–åŸºç¡€åˆ†æ
        analysis = analyze_paper(paper["title"], paper["abstract"])

        # ä¿å®ˆè¯„åˆ†æ ‡å‡†
        base_score = 10  # åŸºç¡€å¼•ç”¨

        # æ–¹æ³•ä¸¥è°¨æ€§åŠ æˆ
        if analysis.research_method == "phylogenetic":
            base_score += 5
        elif analysis.research_method == "experimental":
            base_score += 8

        # ç»Ÿè®¡æ˜¾è‘—æ€§åŠ æˆ
        if "p < 0.001" in paper["abstract"]:
            base_score += 3

        # ä¿å®ˆæŠ˜æ‰£ï¼šä¸æ¿€è¿›é¢„æµ‹
        if analysis.importance_score > 80:
            base_score *= 0.7  # æ€€ç–‘è¿‡é«˜çš„è¯„åˆ†

        return int(base_score)

    def analyze_paper(self, paper: dict[str, Any]) -> dict[str, Any]:
        """ä»ä¿å®ˆç†è®ºè§’åº¦åˆ†æ"""
        prompt = CONSERVATIVE_THEORY_PROMPT.format(
            title=paper["title"],
            abstract=paper["abstract"]
        )

        # è°ƒç”¨LLMè·å–åˆ†æ
        result = analyze_paper(
            paper["title"],
            paper["abstract"],
            custom_prompt=prompt
        )

        return {
            "methodology_score": self._assess_methodology(paper),
            "statistical_rigor": self._assess_statistics(paper),
            "reproducibility": self._check_reproducibility(paper),
            "conservative_rating": self._calculate_conservative_score(result),
        }

    def _assess_methodology(self, paper: dict[str, Any]) -> int:
        """è¯„ä¼°æ–¹æ³•å­¦ä¸¥è°¨æ€§"""
        abstract = paper["abstract"].lower()
        score = 5

        # æ–¹æ³•å­¦å…³é”®è¯
        if "randomized" in abstract or "randomised" in abstract:
            score += 2
        if "replicate" in abstract or "reproducible" in abstract:
            score += 2
        if "sample size" in abstract or "n=" in abstract:
            score += 1

        return min(score, 10)

    def _assess_statistics(self, paper: dict[str, Any]) -> int:
        """è¯„ä¼°ç»Ÿè®¡ä¸¥è°¨æ€§"""
        abstract = paper["abstract"]
        score = 5

        # ç»Ÿè®¡æŒ‡æ ‡
        if "p < 0.05" in abstract or "p<0.05" in abstract:
            score += 1
        if "p < 0.01" in abstract or "p<0.01" in abstract:
            score += 1
        if "confidence interval" in abstract.lower():
            score += 2
        if "effect size" in abstract.lower():
            score += 1

        return min(score, 10)

    def _check_reproducibility(self, paper: dict[str, Any]) -> bool:
        """æ£€æŸ¥å¯é‡å¤æ€§"""
        # æ£€æŸ¥æ˜¯å¦æœ‰ä»£ç /æ•°æ®é“¾æ¥
        has_code = "github" in paper.get("url", "").lower()
        has_data = "supplementary" in paper.get("abstract", "").lower()
        return has_code or has_data

    def _calculate_conservative_score(self, result) -> int:
        """è®¡ç®—ä¿å®ˆè¯„åˆ†"""
        # å¯¹é‡è¦æ€§è¯„åˆ†è¿›è¡Œä¿å®ˆè°ƒæ•´
        original_score = result.importance_score
        if original_score > 70:
            return int(original_score * 0.8)
        return original_score
```

**ç«äº‰åœºåè°ƒå™¨ï¼š**

```python
# src/evo_flywheel/analyzers/arena.py
from typing import Any
import numpy as np

from evo_flywheel.analyzers.agents.conservative import (
    ConservativeTheoryAgent,
    ConservativeAppAgent
)
from evo_flywheel.analyzers.agents.radical import (
    RadicalTheoryAgent,
    RadicalAppAgent
)
from evo_flywheel.db.predictions_crud import (
    save_prediction,
    get_paper_predictions
)

class MultiAgentArena:
    """å¤šæ™ºèƒ½ä½“ç«äº‰åœº"""

    def __init__(self):
        self.agents = [
            ConservativeTheoryAgent(),
            ConservativeAppAgent(),
            RadicalTheoryAgent(),
            RadicalAppAgent(),
        ]

    def evaluate_paper(self, paper: dict[str, Any]) -> dict[str, Any]:
        """è®©æ‰€æœ‰æ™ºèƒ½ä½“è¯„ä¼°åŒä¸€ç¯‡è®ºæ–‡"""

        predictions = {}
        analyses = {}
        confidences = {}

        for agent in self.agents:
            # é¢„æµ‹å½±å“
            pred = agent.predict_impact(paper)
            predictions[agent.name] = pred

            # åˆ†æè®ºæ–‡
            analysis = agent.analyze_paper(paper)
            analyses[agent.name] = analysis

            # è·å–ç½®ä¿¡åº¦
            conf = agent.get_confidence()
            confidences[agent.name] = conf

        # è®¡ç®—åˆ†æ­§åº¦
        pred_values = list(predictions.values())
        disagreement = max(pred_values) - min(pred_values)
        consensus = np.mean(pred_values)
        std = np.std(pred_values)

        # åŠ æƒé¢„æµ‹ï¼ˆåŸºäºæ™ºèƒ½ä½“å£°èª‰ï¼‰
        weighted_pred = self._calculate_weighted_prediction(
            predictions, confidences
        )

        result = {
            "paper_id": paper["id"],
            "paper_title": paper["title"],
            "predictions": predictions,
            "analyses": analyses,
            "confidences": confidences,
            "disagreement": disagreement,
            "consensus": consensus,
            "std": std,
            "weighted_prediction": weighted_pred,
            "recommendation": self._get_recommendation(predictions, analyses),
        }

        # ä¿å­˜é¢„æµ‹
        save_prediction(result)

        return result

    def _calculate_weighted_prediction(
        self,
        predictions: dict[str, int],
        confidences: dict[str, float]
    ) -> float:
        """åŸºäºæ™ºèƒ½ä½“å£°èª‰è®¡ç®—åŠ æƒé¢„æµ‹"""
        total_weight = sum(confidences.values())
        if total_weight == 0:
            return np.mean(list(predictions.values()))

        weighted_sum = sum(
            predictions[name] * conf
            for name, conf in confidences.items()
        )
        return weighted_sum / total_weight

    def _get_recommendation(
        self,
        predictions: dict[str, int],
        analyses: dict[str, Any]
    ) -> str:
        """ç”Ÿæˆæ¨èæ„è§"""
        # æ‰¾å‡ºæœ€é«˜å’Œæœ€ä½é¢„æµ‹
        max_agent = max(predictions, key=predictions.get)
        min_agent = min(predictions, key=predictions.get)

        if predictions[max_agent] - predictions[min_agent] > 50:
            return f"é«˜äº‰è®®ï¼š{max_agent}çœ‹å¥½ï¼Œ{min_agent}çœ‹æ·¡"
        elif predictions[max_agent] > 50:
            return f"å…±è¯†çœ‹å¥½ï¼šå¹³å‡é¢„æµ‹{np.mean(list(predictions.values())):.0f}å¼•ç”¨"
        else:
            return "å…³æ³¨åº¦ä¸€èˆ¬"

    def validate_predictions(self, paper_id: int, actual_citations: int):
        """éªŒè¯é¢„æµ‹ï¼Œæ›´æ–°æ™ºèƒ½ä½“å£°èª‰"""
        predictions = get_paper_predictions(paper_id)

        for pred in predictions:
            agent_name = pred["agent_name"]
            predicted = pred["predicted_citations"]
            error = abs(predicted - actual_citations)

            # æ›´æ–°å¯¹åº”æ™ºèƒ½ä½“çš„å£°èª‰
            for agent in self.agents:
                if agent.name == agent_name:
                    agent.update_reputation(error)
                    break

    def get_leaderboard(self) -> list[dict[str, Any]]:
        """è·å–æ™ºèƒ½ä½“æ’è¡Œæ¦œ"""
        leaderboard = []
        for agent in self.agents:
            leaderboard.append({
                "name": agent.name,
                "role": agent.role,
                "reputation": agent.reputation_score,
                "recent_accuracy": np.mean(agent.accuracy_history[-10:]) if agent.accuracy_history else 0,
                "total_predictions": len(agent.accuracy_history),
            })

        # æŒ‰å£°èª‰æ’åº
        leaderboard.sort(key=lambda x: x["reputation"], reverse=True)
        return leaderboard
```

### 7.3 æ•°æ®åº“æ‰©å±•

**æ–°å¢è¡¨ç»“æ„ï¼š**

```python
# src/evo_flywheel/db/models.py æ–°å¢

class AgentPrediction(Base):
    """æ™ºèƒ½ä½“é¢„æµ‹è®°å½•"""
    __tablename__ = "agent_predictions"

    id = Column(Integer, primary_key=True)
    paper_id = Column(Integer, ForeignKey("papers.id"))
    agent_name = Column(String(100))  # æ™ºèƒ½ä½“åç§°
    agent_role = Column(String(50))   # æ™ºèƒ½ä½“è§’è‰²

    # é¢„æµ‹å†…å®¹
    predicted_citations = Column(Integer)  # é¢„æµ‹å¼•ç”¨æ•°
    predicted_altmetric = Column(Integer)   # é¢„æµ‹Altmetric
    confidence = Column(Float)              # ç½®ä¿¡åº¦

    # åˆ†æç»“æœ
    reasoning = Column(Text)      # é¢„æµ‹ç†ç”±
    analysis = Column(JSON)       # è¯¦ç»†åˆ†æ

    # å…ƒæ•°æ®
    created_at = Column(DateTime, default=datetime.utcnow)
    validated = Column(Boolean, default=False)

    paper = relationship("Paper", back_populates="predictions")


class PaperValidation(Base):
    """è®ºæ–‡çœŸå®éªŒè¯è®°å½•"""
    __tablename__ = "paper_validations"

    id = Column(Integer, primary_key=True)
    paper_id = Column(Integer, ForeignKey("papers.id"))

    # éªŒè¯æŒ‡æ ‡
    actual_citations = Column(Integer)
    actual_altmetric = Column(Integer)
    validation_date = Column(DateTime)

    # æ—©æœŸæŒ‡æ ‡
    early_citations_1month = Column(Integer)
    early_citations_3month = Column(Integer)

    # æŠ€æœ¯å½±å“
    github_stars = Column(Integer)
    dataset_downloads = Column(Integer)

    # é•¿æœŸæŒ‡æ ‡
    landmark_status = Column(Boolean)  # æ˜¯å¦æˆä¸ºç»å…¸
    textbook_citations = Column(Integer)

    validated_at = Column(DateTime, default=datetime.utcnow)


class AgentReputation(Base):
    """æ™ºèƒ½ä½“å£°èª‰è®°å½•"""
    __tablename__ = "agent_reputation"

    id = Column(Integer, primary_key=True)
    agent_name = Column(String(100), unique=True)
    reputation_score = Column(Float, default=0.5)

    # ç»Ÿè®¡
    total_predictions = Column(Integer, default=0)
    correct_predictions = Column(Integer, default=0)
    accuracy_rate = Column(Float, default=0)

    # æ—¶é—´åºåˆ—
    recent_accuracy = Column(JSON)  # æœ€è¿‘10æ¬¡çš„å‡†ç¡®ç‡
    reputation_history = Column(JSON)  # å£°èª‰å†å²

    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)


# æ‰©å±• Paper æ¨¡å‹
Paper.predictions = relationship("AgentPrediction", back_populates="paper")
```

---

## 8. API æ¥å£è®¾è®¡

### 8.1 ç«äº‰åœºç«¯ç‚¹

```
# æ™ºèƒ½ä½“æ’è¡Œæ¦œ
GET /api/arena/leaderboard
Response:
{
  "leaderboard": [
    {
      "rank": 1,
      "name": "Conservative_Theory",
      "role": "ä¿å®ˆæ´¾ç†è®º",
      "reputation": 0.78,
      "recent_accuracy": 0.82,
      "total_predictions": 1250
    },
    ...
  ]
}

# è®ºæ–‡é¢„æµ‹å¯¹å†³
GET /api/arena/papers/{id}/battle
Response:
{
  "paper_id": 12345,
  "title": "è®ºæ–‡æ ‡é¢˜",
  "predictions": {
    "Conservative_Theory": 15,
    "Radical_Theory": 60,
    "Conservative_App": 25,
    "Radical_App": 45
  },
  "disagreement": 45,
  "consensus": 36.25,
  "recommendation": "é«˜äº‰è®®ï¼šRadical_Theoryçœ‹å¥½ï¼ŒConservative_Theoryçœ‹æ·¡",
  "analyses": {
    "Conservative_Theory": {
      "reasoning": "æ–¹æ³•æ ‡å‡†ä½†æ— çªç ´...",
      "methodology_score": 8,
      ...
    },
    ...
  }
}

# é«˜äº‰è®®è®ºæ–‡åˆ—è¡¨
GET /api/arena/controversies?min_disagreement=30&limit=20
Response:
{
  "papers": [
    {
      "paper_id": 12345,
      "title": "è®ºæ–‡æ ‡é¢˜",
      "disagreement": 65,
      "consensus": 40,
      "highest_prediction": 80,
      "lowest_prediction": 15
    },
    ...
  ]
}

# ç”¨æˆ·å‚ä¸é¢„æµ‹
POST /api/arena/predict
Request:
{
  "paper_id": 12345,
  "user_prediction": {
    "citations_1year": 35,
    "confidence": 0.7,
    "reasoning": "æˆ‘è®¤ä¸º..."
  }
}
```

### 8.2 éªŒè¯ç«¯ç‚¹

```
# è§¦å‘éªŒè¯ä»»åŠ¡
POST /api/validation/validate/{paper_id}
Request:
{
  "actual_citations": 42,
  "actual_altmetric": 156
}

# è·å–éªŒè¯å†å²
GET /api/validation/history/{paper_id}
Response:
{
  "predictions": [
    {
      "agent_name": "Conservative_Theory",
      "predicted": 15,
      "actual": 42,
      "error": 27
    },
    ...
  ]
}
```

---

## 9. Streamlit ç•Œé¢è®¾è®¡

### 9.1 ä¸»é¡µé¢å¸ƒå±€

```python
# streamlit/pages/arena.py
import streamlit as st

st.set_page_config(page_title="å­¦æœ¯ç«æŠ€åœº", layout="wide")

# ä¾§è¾¹æ ï¼šæ™ºèƒ½ä½“æ’è¡Œæ¦œ
with st.sidebar:
    st.header("ğŸ† æ™ºèƒ½ä½“æ’è¡Œæ¦œ")
    leaderboard = get_leaderboard()
    for i, agent in enumerate(leaderboard, 1):
        st.metric(
            f"{i}. {agent['name']}",
            f"{agent['reputation']:.1%}",
            help=f"å‡†ç¡®ç‡: {agent['recent_accuracy']:.1%}"
        )

# ä¸»å†…å®¹åŒº
tab1, tab2, tab3 = st.tabs(["ä»Šæ—¥äº‰è®®", "é¢„æµ‹å¯¹å†³", "éªŒè¯å†å²"])

with tab1:
    st.header("ğŸ”¥ é«˜äº‰è®®è®ºæ–‡")
    controversies = get_controversies(limit=20)

    for paper in controversies:
        with st.expander(f"ğŸ“„ {paper['title']}"):
            col1, col2 = st.columns(2)

            with col1:
                st.subheader("é¢„æµ‹åˆ†å¸ƒ")
                # ç»˜åˆ¶é¢„æµ‹åˆ†å¸ƒå›¾
                fig = plot_prediction_distribution(paper['predictions'])
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                st.subheader("åˆ†æ­§åº¦: " + str(paper['disagreement']))
                st.write(f"å…±è¯†: {paper['consensus']:.1f} å¼•ç”¨")

                # å„æ™ºèƒ½ä½“è§‚ç‚¹
                for agent, pred in paper['predictions'].items():
                    st.write(f"**{agent}**: {pred} å¼•ç”¨")

            # ç”¨æˆ·å‚ä¸
            st.divider()
            st.subheader("ä½ çš„é¢„æµ‹")
            user_pred = st.slider(
                "ä½ é¢„æµ‹1å¹´åå¼•ç”¨æ•°ï¼š",
                0, 200, paper['consensus']
            )
            if st.button("æäº¤é¢„æµ‹"):
                submit_user_prediction(paper['paper_id'], user_pred)
                st.success("é¢„æµ‹å·²æäº¤ï¼")

with tab2:
    st.header("âš”ï¸ è®ºæ–‡é¢„æµ‹å¯¹å†³")
    paper_id = st.selectbox(
        "é€‰æ‹©è®ºæ–‡",
        get_recent_papers(),
        format_func=lambda x: x['title']
    )

    if paper_id:
        battle = get_paper_battle(paper_id)
        display_battle_view(battle)

with tab3:
    st.header("âœ… éªŒè¯å†å²")
    validations = get_recent_validations()

    for v in validations:
        with st.expander(f"{v['paper_title']} - {v['validated_at']}"):
            st.metric("å®é™…å¼•ç”¨", v['actual_citations'])

            # å„æ™ºèƒ½ä½“è¡¨ç°
            for agent, pred in v['predictions'].items():
                error = abs(pred - v['actual_citations'])
                st.progress(1 - error/100, f"{agent}: è¯¯å·® {error}")
```

### 9.2 å¯è§†åŒ–ç»„ä»¶

**é¢„æµ‹åˆ†å¸ƒå›¾ï¼š**

```python
def plot_prediction_distribution(predictions):
    """ç»˜åˆ¶æ™ºèƒ½ä½“é¢„æµ‹åˆ†å¸ƒ"""
    import plotly.graph_objects as go

    agents = list(predictions.keys())
    values = list(predictions.values())

    fig = go.Figure(go.Bar(
        x=agents,
        y=values,
        marker_color=[
            'green' if v > np.mean(values) else 'gray'
            for v in values
        ]
    ))

    fig.update_layout(
        title="å„æ™ºèƒ½ä½“å¼•ç”¨é¢„æµ‹",
        xaxis_title="æ™ºèƒ½ä½“",
        yaxis_title="é¢„æµ‹å¼•ç”¨æ•°",
        showlegend=False
    )

    return fig
```

**æ™ºèƒ½ä½“å£°èª‰è¶‹åŠ¿ï¼š**

```python
def plot_reputation_trend(agent_name):
    """ç»˜åˆ¶æ™ºèƒ½ä½“å£°èª‰å†å²è¶‹åŠ¿"""
    history = get_reputation_history(agent_name)

    fig = go.Figure()
    fig.add_trace(go.Scatter(
        x=list(range(len(history))),
        y=history,
        mode='lines',
        name=agent_name
    ))

    fig.update_layout(
        title=f"{agent_name} å£°èª‰è¶‹åŠ¿",
        xaxis_title="é¢„æµ‹æ¬¡æ•°",
        yaxis_title="å£°èª‰åˆ†æ•°"
    )

    return fig
```

---

## 10. éªŒè¯æ•°æ®æº

### 10.1 APIé›†æˆ

| æ•°æ®æº | API | æä¾›æŒ‡æ ‡ | å…è´¹é¢åº¦ | ç”¨é€” |
|--------|-----|----------|----------|------|
| **Crossref** | `/works/{doi}` | å¼•ç”¨æ•° | å…è´¹ | æ ¸å¿ƒå¼•ç”¨æ•°æ® |
| **Altmetric** | `/v1/id/{doi}` | Altmetricè¯„åˆ† | 1000æ¬¡/å¤© | ç¤¾ä¼šå½±å“ |
| **OpenCitations** | `/api/v1/citations/{doi}` | å¼•ç”¨åˆ—è¡¨ | å…è´¹ | å¼•ç”¨ç½‘ç»œ |
| **Europe PMC** | `/MED/{doi}` | å¼•ç”¨+Altmetrics | å…è´¹ | åŒ»å­¦æ–‡çŒ® |
| **GitHub** | REST API | stars, forks | 5000æ¬¡/å°æ—¶ | ä»£ç å½±å“ |
| **Wikipedia** | API | å¼•ç”¨ç»Ÿè®¡ | å…è´¹ | çŸ¥è¯†æ•´åˆ |

### 10.2 æ•°æ®è·å–æ¨¡å—

```python
# src/evo_flywheel/validation/crossref.py
import httpx

def get_citations(doi: str) -> dict:
    """ä»Crossrefè·å–å¼•ç”¨æ•°æ®"""
    url = f"https://api.crossref.org/works/{doi}"
    response = httpx.get(url)
    response.raise_for_status()
    data = response.json()

    return {
        "citations": data["message"].get("is-referenced-by-count", 0),
        "references": len(data["message"].get("reference", [])),
    }

# src/evo_flywheel/validation/altmetric.py
def get_altmetric(doi: str, api_key: str) -> dict:
    """ä»Altmetricè·å–ç¤¾ä¼šå½±å“æ•°æ®"""
    url = f"https://api.altmetric.com/v1/id/doi/{doi}"
    params = {"key": api_key}
    response = httpx.get(url, params=params)
    response.raise_for_status()
    data = response.json()

    return {
        "score": data.get("score", 0),
        "news": len(data.get("cursors", {}).get("news", [])),
        "blogs": len(data.get("cursors", {}).get("blogs", [])),
        "twitter": data.get("cited_by_tweeters_count", 0),
    }
```

---

## 11. å®ç°è·¯çº¿å›¾

### 11.1 Phase 1: å¤šæ™ºèƒ½ä½“æ¡†æ¶ (1-2å‘¨)

**ä»»åŠ¡ï¼š**
- [ ] å®ç° `PaperAgent` åŸºç±»
- [ ] å®ç°4ä¸ªåŸºç¡€æ™ºèƒ½ä½“
- [ ] å®ç°è§’è‰²ç‰¹å®š Prompt æ¨¡æ¿
- [ ] å®ç° `MultiAgentArena` åè°ƒå™¨
- [ ] å•å…ƒæµ‹è¯•

**äº¤ä»˜ç‰©ï¼š**
```bash
src/evo_flywheel/analyzers/
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ __init__.py âœ“
â”‚   â”œâ”€â”€ base.py âœ“
â”‚   â”œâ”€â”€ conservative.py âœ“
â”‚   â””â”€â”€ radical.py âœ“
â””â”€â”€ arena.py âœ“
```

### 11.2 Phase 2: æ•°æ®åº“ä¸éªŒè¯ (3-5å¤©)

**ä»»åŠ¡ï¼š**
- [ ] æ‰©å±•æ•°æ®åº“æ¨¡å‹
- [ ] å®ç° CRUD æ“ä½œ
- [ ] é›†æˆ Crossref API
- [ ] é›†æˆ Altmetric API
- [ ] å®ç°éªŒè¯è°ƒåº¦ä»»åŠ¡

**äº¤ä»˜ç‰©ï¼š**
```bash
src/evo_flywheel/db/models.py âœ“ æ‰©å±•
src/evo_flywheel/validation/
â”œâ”€â”€ crossref.py âœ“
â”œâ”€â”€ altmetric.py âœ“
â””â”€â”€ scheduler.py âœ“
```

### 11.3 Phase 3: API ç«¯ç‚¹ (1å‘¨)

**ä»»åŠ¡ï¼š**
- [ ] æ’è¡Œæ¦œ API
- [ ] é¢„æµ‹å¯¹å†³ API
- [ ] äº‰è®®è®ºæ–‡ API
- [ ] ç”¨æˆ·é¢„æµ‹ API
- [ ] éªŒè¯ API

**äº¤ä»˜ç‰©ï¼š**
```bash
src/evo_flywheel/api/arena.py âœ“
```

### 11.4 Phase 4: Streamlit ç•Œé¢ (1-2å‘¨)

**ä»»åŠ¡ï¼š**
- [ ] æ™ºèƒ½ä½“æ’è¡Œæ¦œé¡µé¢
- [ ] é¢„æµ‹å¯¹å†³é¡µé¢
- [ ] äº‰è®®è®ºæ–‡åˆ—è¡¨
- [ ] ç”¨æˆ·é¢„æµ‹äº¤äº’
- [ ] å¯è§†åŒ–å›¾è¡¨

**äº¤ä»˜ç‰©ï¼š**
```bash
streamlit/pages/
â”œâ”€â”€ arena.py âœ“
â””â”€â”€ predictions.py âœ“
```

### 11.5 Phase 5: è¿›åŒ–ä¸ä¼˜åŒ– (æŒç»­)

**ä»»åŠ¡ï¼š**
- [ ] åŸºäºå†å²æ•°æ®ä¼˜åŒ–æƒé‡
- [ ] ç”Ÿæˆæ–°çš„æ™ºèƒ½ä½“å˜ä½“
- [ ] A/Bæµ‹è¯• Prompt
- [ ] é¢†åŸŸè‡ªé€‚åº”æ™ºèƒ½ä½“
- [ ] ç”¨æˆ·åé¦ˆé›†æˆ

---

## 12. é¢„æœŸæ•ˆæœ

### 12.1 é£è½®åŠ é€ŸæŒ‡æ ‡

| æ—¶é—´èŠ‚ç‚¹ | æ™ºèƒ½ä½“æ•°é‡ | é¢„æµ‹å‡†ç¡®ç‡ | è®ºæ–‡è¦†ç›– |
|----------|-----------|-----------|----------|
| å¯åŠ¨ | 4ä¸ªåŸºç¡€æ™ºèƒ½ä½“ | åŸºå‡† | 30ç¯‡/å¤© |
| 1ä¸ªæœˆ | 4ä¸ª | 50% | 900ç¯‡å†å² |
| 3ä¸ªæœˆ | 5-6ä¸ªï¼ˆè¿›åŒ–ï¼‰ | 55% | 2700ç¯‡ |
| 6ä¸ªæœˆ | 6-8ä¸ªï¼ˆé¢†åŸŸåˆ†åŒ–ï¼‰ | 60% | 5400ç¯‡ |
| 1å¹´ | 8-10ä¸ª | 65%+ | 10000ç¯‡+ |

### 12.2 ä»·å€¼éªŒè¯

**å¯¹ç”¨æˆ·çš„ä»·å€¼ï¼š**
- å‘ç°äº‰è®®æ€§è®ºæ–‡ï¼ˆåˆ†æ­§åº¦é«˜ï¼‰
- ç†è§£ä¸åŒè¯„ä¼°è§†è§’
- å‚ä¸é¢„æµ‹ï¼Œæµ‹è¯•åˆ¤æ–­åŠ›
- æ¯”å•ä¸€æ¨èæ›´ä¸°å¯Œçš„ä¿¡æ¯

**å¯¹å­¦æœ¯ç•Œçš„ä»·å€¼ï¼š**
- æ¢ç´¢å½±å“åŠ›é‡åŒ–
- åŠ é€Ÿé‡è¦ç ”ç©¶ä¼ æ’­
- ä¿ƒè¿›å­¦æœ¯è®¨è®º
- å½¢æˆé¢„æµ‹å¸‚åœº

---

## 13. é£é™©ä¸æŒ‘æˆ˜

### 13.1 æŠ€æœ¯é£é™©

| é£é™© | å½±å“ | ç¼“è§£æªæ–½ |
|------|------|----------|
| é¢„æµ‹å‡†ç¡®ç‡ä½äºé¢„æœŸ | ç”¨æˆ·æµå¤± | å¤šç»´åº¦æŒ‡æ ‡ï¼Œæ—©æœŸéªŒè¯ |
| APIé™æµ | æ•°æ®ç¼ºå¤± | ç¼“å­˜+å¤šæºæ•´åˆ |
| æ™ºèƒ½ä½“åŒè´¨åŒ– | åˆ†æ­§åº¦ä½ | å¼ºè°ƒè§’è‰²å·®å¼‚åŒ– |
| éªŒè¯å‘¨æœŸé•¿ | åé¦ˆå»¶è¿Ÿ | ä»£ç†æŒ‡æ ‡æå‰éªŒè¯ |

### 13.2 è®¾è®¡æŒ‘æˆ˜

**æŒ‘æˆ˜1ï¼šå¦‚ä½•é¿å…æ™ºèƒ½ä½“è¶‹åŒï¼Ÿ**
- æ–¹æ¡ˆï¼šå¼ºåŒ–è§’è‰²çº¦æŸï¼Œä¸åŒçš„Prompt
- æ–¹æ¡ˆï¼šæƒ©ç½šè¿‡åº¦ç›¸ä¼¼çš„é¢„æµ‹

**æŒ‘æˆ˜2ï¼šå¦‚ä½•å¤„ç†é¢†åŸŸå·®å¼‚ï¼Ÿ**
- æ–¹æ¡ˆï¼šåˆ†é¢†åŸŸè®­ç»ƒ
- æ–¹æ¡ˆï¼šé¢†åŸŸä¸“ç”¨æ™ºèƒ½ä½“

**æŒ‘æˆ˜3ï¼šå¦‚ä½•æ¿€åŠ±ç”¨æˆ·å‚ä¸ï¼Ÿ**
- æ–¹æ¡ˆï¼šç”¨æˆ·å£°èª‰ç³»ç»Ÿ
- æ–¹æ¡ˆï¼šé¢„æµ‹å‡†ç¡®ç‡æ’è¡Œ

---

## 14. æœªæ¥æ‰©å±•

### 14.1 æ™ºèƒ½ä½“è¿›åŒ–

```python
# è‡ªåŠ¨ç”Ÿæˆæ–°æ™ºèƒ½ä½“
class AgentEvolution:
    def evolve(self, performance_history):
        """åŸºäºå†å²è¡¨ç°ç”Ÿæˆæ–°æ™ºèƒ½ä½“"""
        # è¯†åˆ«è¡¨ç°å¥½çš„æ¨¡å¼
        successful_patterns = self._extract_patterns(performance_history)

        # ç”Ÿæˆæ–°æ™ºèƒ½ä½“
        new_agents = []
        for pattern in successful_patterns:
            new_agent = self._generate_agent(pattern)
            new_agents.append(new_agent)

        # A/Bæµ‹è¯•
        return self._ab_test(new_agents)
```

### 14.2 ç”¨æˆ·å‚ä¸å¸‚åœº

```python
# é¢„æµ‹å¸‚åœº
class PredictionMarket:
    def create_market(self, paper):
        """ä¸ºæ¯ç¯‡è®ºæ–‡åˆ›å»ºé¢„æµ‹å¸‚åœº"""
        market = {
            "paper_id": paper["id"],
            "contracts": [],
            "traders": [],
        }

        # åˆ›å»ºä¸åŒé¢„æµ‹çš„åˆçº¦
        for tier in ["low", "medium", "high"]:
            contract = {
                "type": tier,
                "price": self._initial_price(tier),
                "volume": 0,
            }
            market["contracts"].append(contract)

        return market
```

---

## 15. å‚è€ƒèµ„æ–™

### 15.1 ç›¸å…³ç ”ç©¶

1. **AI-Trader** (HKU)
   - GitHub: https://github.com/HKUDS/AI-Trader
   - ç›´æ’­: https://ai4trade.ai

2. **TradingAgents** (BAAI)
   - è®ºæ–‡: https://arxiv.org/abs/2412.20138
   - å¤šè§’è‰²åä½œæ¡†æ¶

3. **Alpha Arena**
   - ä¸»åŠæ–¹: nof1.ai
   - 6ä¸ªAIæ¨¡å‹å®ç›˜äº¤æ˜“

### 15.2 å­¦æœ¯æŒ‡æ ‡ç ”ç©¶

1. **æ›¿ä»£è®¡é‡å­¦**
   - Altmetric.com
   - Plum Analytics
   - Impactstory

2. **å¼•ç”¨åˆ†æ**
   - Crossref
   - OpenCitations
   - Europe PMC

3. **ç§‘å­¦å­¦**
   - Fortunato et al. (2018) - Science of science
   - Wang et al. (2013) - Science of science

---

## é™„å½• Aï¼šæœ¯è¯­è¡¨

| æœ¯è¯­ | å®šä¹‰ |
|------|------|
| **æ™ºèƒ½ä½“** | å…·æœ‰ç‰¹å®šè¯„ä¼°ç­–ç•¥çš„AIè§’è‰² |
| **åˆ†æ­§åº¦** | å„æ™ºèƒ½ä½“é¢„æµ‹å€¼çš„æå·® |
| **å…±è¯†** | å„æ™ºèƒ½ä½“é¢„æµ‹çš„å‡å€¼ |
| **å£°èª‰åˆ†æ•°** | æ™ºèƒ½ä½“å†å²é¢„æµ‹å‡†ç¡®ç‡çš„ç»¼åˆè¯„åˆ† |
| **éªŒè¯** | å°†é¢„æµ‹å€¼ä¸çœŸå®å€¼å¯¹æ¯”çš„è¿‡ç¨‹ |
| **é£è½®** | æŒç»­è‡ªæˆ‘å¼ºåŒ–çš„å¾ªç¯ç³»ç»Ÿ |

---

## é™„å½• Bï¼šé…ç½®ç¤ºä¾‹

```yaml
# config/arena.yaml
arena:
  # æ™ºèƒ½ä½“é…ç½®
  agents:
    - name: conservative_theory
      role: ä¿å®ˆæ´¾ç†è®º
      model: glm-4-flash
      temperature: 0.3

    - name: radical_theory
      role: æ¿€è¿›æ´¾ç†è®º
      model: glm-4-flash
      temperature: 0.8

  # éªŒè¯é…ç½®
  validation:
    crossref:
      enabled: true
      api_url: https://api.crossref.org/works

    altmetric:
      enabled: true
      api_key: ${ALTMETRIC_API_KEY}

  # è°ƒåº¦é…ç½®
  schedule:
    collection: "0 9 * * *"      # æ¯å¤©9ç‚¹é‡‡é›†
    validation: "0 9 * * 0"      # æ¯å‘¨æ—¥éªŒè¯
    evolution: "0 9 1 * *"       # æ¯æœˆ1æ—¥è¿›åŒ–
```

---

**æ–‡æ¡£ç»“æŸ**

*æœ¬æ–‡æ¡£æ˜¯ Evo-Flywheel é¡¹ç›®å¤šæ™ºèƒ½ä½“ç«äº‰æ¡†æ¶çš„è®¾è®¡è¯´æ˜ã€‚å¦‚æœ‰é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·è”ç³»é¡¹ç›®ç»´æŠ¤è€…ã€‚*
